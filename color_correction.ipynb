{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Correction with image\n",
    "this notebook is to testout image color correction and extracting required info from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] finding color matching cards...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.aruco' has no attribute 'DetectorParameters_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 80\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# display the reference and input images to our screen\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# cv2.imshow(\"Reference\", ref)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# cv2.imshow(\"Input\", image)\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# find the color matching card in each image\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] finding color matching cards...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m refCard \u001b[38;5;241m=\u001b[39m \u001b[43mfind_color_card\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m imageCard \u001b[38;5;241m=\u001b[39m find_color_card(image)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# if the color matching card is not found in either the reference\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# image or the input image, gracefully exit\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m, in \u001b[0;36mfind_color_card\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_color_card\u001b[39m(image):\n\u001b[0;32m     11\u001b[0m \t\u001b[38;5;66;03m# load the ArUCo dictionary, grab the ArUCo parameters, and\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \t\u001b[38;5;66;03m# detect the markers in the input image\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \t\u001b[38;5;66;03m# arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \tarucoDict \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maruco\u001b[38;5;241m.\u001b[39mgetPredefinedDictionary(cv2\u001b[38;5;241m.\u001b[39maruco\u001b[38;5;241m.\u001b[39mDICT_ARUCO_ORIGINAL)\n\u001b[1;32m---> 15\u001b[0m \tarucoParams \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maruco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetectorParameters_create\u001b[49m()\n\u001b[0;32m     17\u001b[0m \t(corners, ids, rejected) \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maruco\u001b[38;5;241m.\u001b[39mdetectMarkers(image,\n\u001b[0;32m     18\u001b[0m \t\tarucoDict, parameters\u001b[38;5;241m=\u001b[39marucoParams)\n\u001b[0;32m     20\u001b[0m \t\u001b[38;5;66;03m# try to extract the coordinates of the color correction card\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.aruco' has no attribute 'DetectorParameters_create'"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils.perspective import four_point_transform\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "def find_color_card(image):\n",
    "\t# load the ArUCo dictionary, grab the ArUCo parameters, and\n",
    "\t# detect the markers in the input image\n",
    "\t# arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL)\n",
    "\tarucoDict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_ARUCO_ORIGINAL)\n",
    "\t# arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\tarucoParams = cv2.aruco.DetectorParameters\n",
    "\t\n",
    "\t\n",
    "\t(corners, ids, rejected) = cv2.aruco.detectMarkers(image,\n",
    "\t\tarucoDict, parameters=arucoParams)\n",
    "\t\n",
    "\t# try to extract the coordinates of the color correction card\n",
    "\ttry:\n",
    "\t\t# otherwise, we've found the four ArUco markers, so we can\n",
    "\t\t# continue by flattening the ArUco IDs list\n",
    "\t\tids = ids.flatten()\n",
    "\n",
    "\t\t# extract the top-left marker\n",
    "\t\ti = np.squeeze(np.where(ids == 923))\n",
    "\t\ttopLeft = np.squeeze(corners[i])[0]\n",
    "\n",
    "\t\t# extract the top-right marker\n",
    "\t\ti = np.squeeze(np.where(ids == 1001))\n",
    "\t\ttopRight = np.squeeze(corners[i])[1]\n",
    "\n",
    "\t\t# extract the bottom-right marker\n",
    "\t\ti = np.squeeze(np.where(ids == 241))\n",
    "\t\tbottomRight = np.squeeze(corners[i])[2]\n",
    "\n",
    "\t\t# extract the bottom-left marker\n",
    "\t\ti = np.squeeze(np.where(ids == 1007))\n",
    "\t\tbottomLeft = np.squeeze(corners[i])[3]\n",
    "\n",
    "\t# we could not find color correction card, so gracefully return\n",
    "\texcept:\n",
    "\t\treturn None\n",
    "\n",
    "\t# build our list of reference points and apply a perspective\n",
    "\t# transform to obtain a top-down, birdseye view of the color\n",
    "\t# matching card\n",
    "\tcardCoords = np.array([topLeft, topRight,\n",
    "\t\tbottomRight, bottomLeft])\n",
    "\tcard = four_point_transform(image, cardCoords)\n",
    "\n",
    "\t# return the color matching card to the calling function\n",
    "\treturn card\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-r\", \"--reference\", required=False,\n",
    "# \thelp=\"path to the input reference image\")\n",
    "# ap.add_argument(\"-i\", \"--input\", required=False,\n",
    "# \thelp=\"path to the input image to apply color correction to\")\n",
    "# args = vars(ap.parse_args())\n",
    "args = {\"reference\": \"./NeoJaundice/images/0001-1.jpg\",\"input\":\"./NeoJaundice/images/0001-1.jpg\"}\n",
    "\n",
    "# load the reference image and input images from disk\n",
    "print(\"[INFO] loading images...\")\n",
    "ref = cv2.imread(args[\"reference\"])\n",
    "image = cv2.imread(args[\"input\"])\n",
    "\n",
    "# resize the reference and input images\n",
    "ref = imutils.resize(ref, width=600)\n",
    "image = imutils.resize(image, width=600)\n",
    "\n",
    "# display the reference and input images to our screen\n",
    "# cv2.imshow(\"Reference\", ref)\n",
    "# cv2.imshow(\"Input\", image)\n",
    "\n",
    "# find the color matching card in each image\n",
    "print(\"[INFO] finding color matching cards...\")\n",
    "refCard = find_color_card(ref)\n",
    "imageCard = find_color_card(image)\n",
    "\n",
    "# if the color matching card is not found in either the reference\n",
    "# image or the input image, gracefully exit\n",
    "if refCard is None or imageCard is None:\n",
    "\tprint(\"[INFO] could not find color matching card in both images\")\n",
    "\tsys.exit(0)\n",
    "\n",
    "# show the color matching card in the reference image and input image,\n",
    "# respectively\n",
    "# cv2.imshow(\"Reference Color Card\", refCard)\n",
    "# cv2.imshow(\"Input Color Card\", imageCard)\n",
    "\n",
    "# apply histogram matching from the color matching card in the\n",
    "# reference image to the color matching card in the input image\n",
    "print(\"[INFO] matching images...\")\n",
    "imageCard = exposure.match_histograms(imageCard, refCard,\n",
    "\tmultichannel=True)\n",
    "\n",
    "cv2.imwrite(\"final.jpg\",imageCard)\n",
    "\n",
    "# show our input color matching card after histogram matching\n",
    "# cv2.imshow(\"Input Color Card After Matching\", imageCard)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
